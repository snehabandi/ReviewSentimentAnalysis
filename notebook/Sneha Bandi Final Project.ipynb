{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eb914dbd",
   "metadata": {},
   "source": [
    "<center><h1>Final Project</h1></center>\n",
    "Name : Sneha Bandi\n",
    "<br>github username : snehabandi\n",
    "<br>USC ID : 6557-6891-44\n",
    "<br><hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fe5fc",
   "metadata": {},
   "source": [
    "<h2><center>Part b) Data Exploration and Pre-processing</center></h2><hr>\n",
    "<b> \n",
    "<br>(i) You can use binary encoding for the sentiments , i.e y=1 for positive sentiments and y=−1 for negative sentiments.\n",
    "</b>\n",
    "<b>\n",
    "<br>ii.) The data are pretty clean. Remove the punctuation and numbers from the data</b>\n",
    "<br>\n",
    "<b><br>(iii)The name of each text file starts with cv number. Use text files 0-699 in each class for training and 700-999 for testing</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c2dc994",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "\n",
    "warnings.filterwarnings('ignore')  # Used to avoid any warnings in the output\n",
    "\n",
    "def train_test_split():\n",
    "    pn = ['neg','pos']\n",
    "    col = [\"reviews\", \"encoding\"]\n",
    "    df_test = pd.DataFrame(columns=col)\n",
    "    df_train = pd.DataFrame(columns=col)\n",
    "    df_complete = pd.DataFrame(columns=col)\n",
    "    k = 0\n",
    "    j = 0\n",
    "    l = 0\n",
    "    for p in range(0,2):\n",
    "        pos_or_neg = pn[p]\n",
    "        \n",
    "        if(pos_or_neg == 'pos'):\n",
    "            encoding = 1\n",
    "        else :\n",
    "            encoding = 0\n",
    "        \n",
    "        i = 0\n",
    "        dir_path = os.getcwd() + '\\..\\data\\\\'+pos_or_neg\n",
    "\n",
    "        for file in os.listdir(dir_path) :\n",
    "            file_path = dir_path + \"\\\\\" +file\n",
    "\n",
    "            with open(file_path) as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "                if i<700:\n",
    "                    df_train.loc[k,'reviews'] = lines \n",
    "                    df_train.loc[k,'encoding'] = encoding\n",
    "                    k = k+1\n",
    "                else:\n",
    "                    df_test.loc[j,'reviews'] = lines \n",
    "                    df_test.loc[j,'encoding'] = encoding\n",
    "                    j = j+1\n",
    "\n",
    "                df_complete.loc[l,'reviews'] = lines \n",
    "                df_complete.loc[l,'encoding'] = encoding\n",
    "\n",
    "                i = i+1\n",
    "                l = l+1\n",
    "\n",
    "    return df_train, df_test,df_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69f9d775",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMPLETE DATA : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[plot : two teen couples go to a church party ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the happy bastard's quick movie review \\n, da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[it is movies like these that make a jaded mov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ \" quest for camelot \" is warner bros . ' fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[synopsis : a mentally unstable man undergoing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>[wow ! what a movie . \\n, it's everything a mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>[richard gere can be a commanding actor , but ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>[glory--starring matthew broderick , denzel wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>[steven spielberg's second epic film on world ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>[truman ( \" true-man \" ) burbank is the perfec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews encoding\n",
       "0     [plot : two teen couples go to a church party ...        0\n",
       "1     [the happy bastard's quick movie review \\n, da...        0\n",
       "2     [it is movies like these that make a jaded mov...        0\n",
       "3     [ \" quest for camelot \" is warner bros . ' fir...        0\n",
       "4     [synopsis : a mentally unstable man undergoing...        0\n",
       "...                                                 ...      ...\n",
       "1995  [wow ! what a movie . \\n, it's everything a mo...        1\n",
       "1996  [richard gere can be a commanding actor , but ...        1\n",
       "1997  [glory--starring matthew broderick , denzel wa...        1\n",
       "1998  [steven spielberg's second epic film on world ...        1\n",
       "1999  [truman ( \" true-man \" ) burbank is the perfec...        1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING DATA : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[plot : two teen couples go to a church party ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the happy bastard's quick movie review \\n, da...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[it is movies like these that make a jaded mov...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ \" quest for camelot \" is warner bros . ' fir...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[synopsis : a mentally unstable man undergoing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>[who would have thought ? \\n, jim carrey does ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>[capsule : this is a harrowing look at a rarel...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>[another 'independent film' , this comedy , wh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>[a frequent error is the categorization of a t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>[very few people would be unaware of beavis &amp; ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews encoding\n",
       "0     [plot : two teen couples go to a church party ...        0\n",
       "1     [the happy bastard's quick movie review \\n, da...        0\n",
       "2     [it is movies like these that make a jaded mov...        0\n",
       "3     [ \" quest for camelot \" is warner bros . ' fir...        0\n",
       "4     [synopsis : a mentally unstable man undergoing...        0\n",
       "...                                                 ...      ...\n",
       "1395  [who would have thought ? \\n, jim carrey does ...        1\n",
       "1396  [capsule : this is a harrowing look at a rarel...        1\n",
       "1397  [another 'independent film' , this comedy , wh...        1\n",
       "1398  [a frequent error is the categorization of a t...        1\n",
       "1399  [very few people would be unaware of beavis & ...        1\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING DATA : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ \" the beach \" is a structurally confusing fi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[the most absurd remake of 1998 ? \\n, it's a t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[in 1990 , the surprise success an unheralded ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[these days , we are witnessing the deluge of ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[after 1993's \" falling down , \" i hoped that ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>[wow ! what a movie . \\n, it's everything a mo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>[richard gere can be a commanding actor , but ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>[glory--starring matthew broderick , denzel wa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>[steven spielberg's second epic film on world ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>[truman ( \" true-man \" ) burbank is the perfec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews encoding\n",
       "0    [ \" the beach \" is a structurally confusing fi...        0\n",
       "1    [the most absurd remake of 1998 ? \\n, it's a t...        0\n",
       "2    [in 1990 , the surprise success an unheralded ...        0\n",
       "3    [these days , we are witnessing the deluge of ...        0\n",
       "4    [after 1993's \" falling down , \" i hoped that ...        0\n",
       "..                                                 ...      ...\n",
       "595  [wow ! what a movie . \\n, it's everything a mo...        1\n",
       "596  [richard gere can be a commanding actor , but ...        1\n",
       "597  [glory--starring matthew broderick , denzel wa...        1\n",
       "598  [steven spielberg's second epic film on world ...        1\n",
       "599  [truman ( \" true-man \" ) burbank is the perfec...        1\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset, test_dataset, dataset = train_test_split()\n",
    "print('\\nCOMPLETE DATA : ')\n",
    "display(dataset)\n",
    "print('\\nTRAINING DATA : ')\n",
    "display(train_dataset)\n",
    "print('\\nTESTING DATA : ')\n",
    "display(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b855e3e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "\n",
    "def review_to_words1( raw_review ):\n",
    "    i=0\n",
    "    df_tokenized = pd.DataFrame(columns=['reviews'])\n",
    "    df_token_dict = pd.DataFrame(columns=['tokens'])\n",
    "\n",
    "    for i in range(0,len(raw_review)):\n",
    "        temp = str(raw_review[\"reviews\"][i])\n",
    "        letters_only = re.sub(r'[\\d]|[^\\w\\s]',' ', temp)\n",
    "        df_tokenized.loc[i,'reviews'] = letters_only\n",
    "\n",
    "    df_tokenized['encoding'] = raw_review['encoding']\n",
    "    return df_tokenized\n",
    "\n",
    "def review_to_words( raw_review ):\n",
    "    i=0\n",
    "    df_tokenized = pd.DataFrame(columns=['reviews'])\n",
    "    df_token_dict = pd.DataFrame(columns=['tokens'])\n",
    "\n",
    "    for doc in raw_review[\"reviews\"]:\n",
    "        \n",
    "        t = Tokenizer(\n",
    "            num_words=None,\n",
    "            filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n1234567890',\n",
    "            lower=True,\n",
    "            split=None,\n",
    "            char_level=False,\n",
    "            oov_token=None,\n",
    "            document_count=0)\n",
    "        \n",
    "        t.fit_on_texts(doc)\n",
    "        token_dict = t.word_counts\n",
    "        tokens = list(token_dict.keys())\n",
    "        df_tokenized.loc[i,'reviews'] = ' '.join(tokens)\n",
    "        i=i+1\n",
    "\n",
    "    df_tokenized['encoding'] = raw_review['encoding']\n",
    "    return df_tokenized\n",
    "\n",
    "def get_word_dict(df_tokenized):\n",
    "        \n",
    "    t = Tokenizer(5001)\n",
    "    t.fit_on_texts(df_tokenized['reviews'])\n",
    "    token_dict = t.word_counts\n",
    "    \n",
    "    return token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ceb27be6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMPLETE DATA : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot two teen couples go to a church party dri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the happy bastard's quick movie review damn th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quest for camelot is warner bros ' first featu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis a mentally unstable man undergoing ps...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>wow what a movie it's everything can be funny ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>richard gere can be a commanding actor but he'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>glorystarring matthew broderick denzel washing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>steven spielberg's second epic film on world w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>truman trueman burbank is the perfect name for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews encoding\n",
       "0     plot two teen couples go to a church party dri...        0\n",
       "1     the happy bastard's quick movie review damn th...        0\n",
       "2     it is movies like these that make a jaded movi...        0\n",
       "3     quest for camelot is warner bros ' first featu...        0\n",
       "4     synopsis a mentally unstable man undergoing ps...        0\n",
       "...                                                 ...      ...\n",
       "1995  wow what a movie it's everything can be funny ...        1\n",
       "1996  richard gere can be a commanding actor but he'...        1\n",
       "1997  glorystarring matthew broderick denzel washing...        1\n",
       "1998  steven spielberg's second epic film on world w...        1\n",
       "1999  truman trueman burbank is the perfect name for...        1\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING DATA : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plot two teen couples go to a church party dri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the happy bastard's quick movie review damn th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>it is movies like these that make a jaded movi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>quest for camelot is warner bros ' first featu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synopsis a mentally unstable man undergoing ps...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>who would have thought jim carrey does drama w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>capsule this is a harrowing look at rarely dra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>another 'independent film' this comedy which w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>a frequent error is the categorization of terr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>very few people would be unaware of beavis but...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews encoding\n",
       "0     plot two teen couples go to a church party dri...        0\n",
       "1     the happy bastard's quick movie review damn th...        0\n",
       "2     it is movies like these that make a jaded movi...        0\n",
       "3     quest for camelot is warner bros ' first featu...        0\n",
       "4     synopsis a mentally unstable man undergoing ps...        0\n",
       "...                                                 ...      ...\n",
       "1395  who would have thought jim carrey does drama w...        1\n",
       "1396  capsule this is a harrowing look at rarely dra...        1\n",
       "1397  another 'independent film' this comedy which w...        1\n",
       "1398  a frequent error is the categorization of terr...        1\n",
       "1399  very few people would be unaware of beavis but...        1\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TESTING DATA : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the beach is a structurally confusing film tha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the most absurd remake of it's a toss up betwe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>in the surprise success an unheralded little m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>these days we are witnessing the deluge of fil...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>after 's falling down i hoped that joel schuma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>wow what a movie it's everything can be funny ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>richard gere can be a commanding actor but he'...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>glorystarring matthew broderick denzel washing...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>steven spielberg's second epic film on world w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>truman trueman burbank is the perfect name for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews encoding\n",
       "0    the beach is a structurally confusing film tha...        0\n",
       "1    the most absurd remake of it's a toss up betwe...        0\n",
       "2    in the surprise success an unheralded little m...        0\n",
       "3    these days we are witnessing the deluge of fil...        0\n",
       "4    after 's falling down i hoped that joel schuma...        0\n",
       "..                                                 ...      ...\n",
       "595  wow what a movie it's everything can be funny ...        1\n",
       "596  richard gere can be a commanding actor but he'...        1\n",
       "597  glorystarring matthew broderick denzel washing...        1\n",
       "598  steven spielberg's second epic film on world w...        1\n",
       "599  truman trueman burbank is the perfect name for...        1\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tokenized_complete = review_to_words(dataset)\n",
    "print('\\nCOMPLETE DATA : ')\n",
    "display(df_tokenized_complete)\n",
    "df_tokenized_train = review_to_words(train_dataset)\n",
    "print('\\nTRAINING DATA : ')\n",
    "display (df_tokenized_train)\n",
    "df_tokenized_test = review_to_words(test_dataset)\n",
    "print('\\nTESTING DATA : ')\n",
    "display (df_tokenized_test)\n",
    "\n",
    "word_dict = get_word_dict(df_tokenized_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae87b171",
   "metadata": {},
   "source": [
    "<b>iv) Count the number of unique words in the whole dataset (train + test) and print it out.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c09c7a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique words in whole dataset are :  48555\n"
     ]
    }
   ],
   "source": [
    "# jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "text_data = []\n",
    "for row in df_tokenized_complete['reviews']:\n",
    "    text_data.extend(row.split(\" \"))\n",
    "bag_of_words = set(text_data)\n",
    "print(\"The number of unique words in whole dataset are : \",len(set(text_data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01248e97",
   "metadata": {},
   "source": [
    "<b><br>(v) Calculate the average review length and the standard deviation of review lengths. Report the results</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8949e948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average length of a line is :  336.4785\n",
      "The standard deviation of review lengths is :  113.17446062495726\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "len_list = []\n",
    "for doc in df_tokenized_complete['reviews']:\n",
    "    sum = sum + len(set(doc.split(' ')))\n",
    "    len_list.append(len(set(doc.split(' '))))\n",
    "avg_len = sum/len(len_list)\n",
    "print(\"The average length of a line is : \",avg_len)\n",
    "print(\"The standard deviation of review lengths is : \",np.std(len_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23f6c86",
   "metadata": {},
   "source": [
    "<b><br>(vi) Plot the histogram of review lengths.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a32927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Count'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=len_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3cd3ed",
   "metadata": {},
   "source": [
    "<b><br>(vii) To represent each text (= data point), there are many ways. In NLP/Deep Learning terminology, this task is called tokenization. It is common to represent text using popularity/ rank of words in text. The most common word in the text will be represented as 1, the second most common word will be represented as 2, etc. Tokenize each text document using this method.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41685b42",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Encoded rank list is : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[876, 1025, 85, 24, 734, 1997, 1996, 43, 109, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1999, 175, 14, 118, 1524, 244, 77, 1957, 4, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1934, 1995, 726, 1470, 827, 1957, 1003, 1996,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[52, 1922, 4, 1995, 38, 21, 138, 1019, 13, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[66, 1996, 29, 15, 760, 3, 2, 40, 217, 1702, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>[1726, 1113, 1631, 306, 116, 35, 964, 227, 144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>[46, 1895, 1995, 1996, 19, 605, 1718, 95, 5, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>[789, 1, 1, 1895, 488, 1318, 1495, 140, 1776, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>[1996, 35, 12, 1995, 1999, 1, 1998, 31, 1917, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>[966, 697, 842, 1113, 1770, 24, 1998, 8, 7, 62...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews\n",
       "0     [876, 1025, 85, 24, 734, 1997, 1996, 43, 109, ...\n",
       "1     [1999, 175, 14, 118, 1524, 244, 77, 1957, 4, 2...\n",
       "2     [1934, 1995, 726, 1470, 827, 1957, 1003, 1996,...\n",
       "3     [52, 1922, 4, 1995, 38, 21, 138, 1019, 13, 1, ...\n",
       "4     [66, 1996, 29, 15, 760, 3, 2, 40, 217, 1702, 3...\n",
       "...                                                 ...\n",
       "1395  [1726, 1113, 1631, 306, 116, 35, 964, 227, 144...\n",
       "1396  [46, 1895, 1995, 1996, 19, 605, 1718, 95, 5, 1...\n",
       "1397  [789, 1, 1, 1895, 488, 1318, 1495, 140, 1776, ...\n",
       "1398  [1996, 35, 12, 1995, 1999, 1, 1998, 31, 1917, ...\n",
       "1399  [966, 697, 842, 1113, 1770, 24, 1998, 8, 7, 62...\n",
       "\n",
       "[1400 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Encoded rank list is : \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1999, 52, 1995, 1996, 2, 80, 1724, 1957, 1524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1999, 1181, 50, 73, 1998, 1290, 1996, 9, 1412...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1994, 1999, 181, 187, 1783, 1, 915, 1524, 292...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[827, 246, 1010, 1781, 11, 1999, 3, 1998, 823,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1063, 335, 78, 639, 1524, 25, 1957, 47, 17, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>[28, 1346, 1996, 1524, 1290, 397, 1205, 1770, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>[110, 11, 1205, 1770, 1996, 30, 397, 1899, 613...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>[1, 86, 22, 15, 41, 1998, 32, 1, 1999, 305, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>[97, 20, 302, 69, 1724, 1858, 569, 172, 90, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>[30, 1, 9, 1995, 1999, 250, 315, 1922, 116, 16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "0    [1999, 52, 1995, 1996, 2, 80, 1724, 1957, 1524...\n",
       "1    [1999, 1181, 50, 73, 1998, 1290, 1996, 9, 1412...\n",
       "2    [1994, 1999, 181, 187, 1783, 1, 915, 1524, 292...\n",
       "3    [827, 246, 1010, 1781, 11, 1999, 3, 1998, 823,...\n",
       "4    [1063, 335, 78, 639, 1524, 25, 1957, 47, 17, 1...\n",
       "..                                                 ...\n",
       "595  [28, 1346, 1996, 1524, 1290, 397, 1205, 1770, ...\n",
       "596  [110, 11, 1205, 1770, 1996, 30, 397, 1899, 613...\n",
       "597  [1, 86, 22, 15, 41, 1998, 32, 1, 1999, 305, 10...\n",
       "598  [97, 20, 302, 69, 1724, 1858, 569, 172, 90, 19...\n",
       "599  [30, 1, 9, 1995, 1999, 250, 315, 1922, 116, 16...\n",
       "\n",
       "[600 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Replace words by rank\n",
    "def get_text_sequence(df_complete, df_convert):\n",
    "#     display(df_complete)\n",
    "#     display(df_convert)\n",
    "    df_text_to_seq = pd.DataFrame(columns=['reviews'])\n",
    "    t = Tokenizer(5001)\n",
    "    t.fit_on_texts(df_complete['reviews'])\n",
    "    i=0\n",
    "    for doc in df_convert[\"reviews\"]:\n",
    "        sublist = t.texts_to_sequences(doc)\n",
    "        df_text_to_seq.loc[i,'reviews'] = sublist\n",
    "        i = i+1\n",
    "    return df_text_to_seq\n",
    "\n",
    "df_encoded_train = pd.DataFrame(columns=[\"reviews\"])\n",
    "df_encoded_test = pd.DataFrame(columns=[\"reviews\"])\n",
    "i = 0\n",
    "for doc in df_tokenized_train['reviews']:\n",
    "    doc = [word.replace(word, str(word_dict[word])) for word in doc.split(' ')]\n",
    "    df_encoded_train.loc[i,'reviews'] = doc\n",
    "    i = i+1\n",
    "\n",
    "    \n",
    "i = 0\n",
    "for doc in df_tokenized_test['reviews']:\n",
    "    doc = [word.replace(word, str(word_dict[word])) for word in doc.split(\" \")]\n",
    "    df_encoded_test.loc[i,'reviews'] = doc\n",
    "    i = i+1\n",
    "    \n",
    "print(\"Train Encoded rank list is : \")\n",
    "display(df_encoded_train)\n",
    "print(\"Test Encoded rank list is : \")\n",
    "display(df_encoded_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e09500",
   "metadata": {},
   "source": [
    "<b><br>(viii) Select a review length L that 70% of the reviews have a length below it. If you feel more adventurous, set the threshold to 90%</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29dbcdcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review length 383 has 70 percent of the reviews length below it.\n"
     ]
    }
   ],
   "source": [
    "#Sort lengths in increasing order and pick 1400th length as 70%\n",
    "len_list.sort()\n",
    "L = len_list[1400]\n",
    "print(\"Review length %d has 70 percent of the reviews length below it.\" %(L))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d80ea3a",
   "metadata": {},
   "source": [
    "<b><br>(ix) Truncate reviews longer than L words and zero-pad reviews shorter than L so that all texts (= data points) are of length L</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7cf2d46f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[876, 1025, 85, 24, 734, 1997, 1996, 43, 109, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1999, 175, 14, 118, 1524, 244, 77, 1957, 4, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1934, 1995, 726, 1470, 827, 1957, 1003, 1996,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[52, 1922, 4, 1995, 38, 21, 138, 1019, 13, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[66, 1996, 29, 15, 760, 3, 2, 40, 217, 1702, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>[1726, 1113, 1631, 306, 116, 35, 964, 227, 144...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>[46, 1895, 1995, 1996, 19, 605, 1718, 95, 5, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>[789, 1, 1, 1895, 488, 1318, 1495, 140, 1776, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>[1996, 35, 12, 1995, 1999, 1, 1998, 31, 1917, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>[966, 697, 842, 1113, 1770, 24, 1998, 8, 7, 62...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                reviews\n",
       "0     [876, 1025, 85, 24, 734, 1997, 1996, 43, 109, ...\n",
       "1     [1999, 175, 14, 118, 1524, 244, 77, 1957, 4, 2...\n",
       "2     [1934, 1995, 726, 1470, 827, 1957, 1003, 1996,...\n",
       "3     [52, 1922, 4, 1995, 38, 21, 138, 1019, 13, 1, ...\n",
       "4     [66, 1996, 29, 15, 760, 3, 2, 40, 217, 1702, 3...\n",
       "...                                                 ...\n",
       "1395  [1726, 1113, 1631, 306, 116, 35, 964, 227, 144...\n",
       "1396  [46, 1895, 1995, 1996, 19, 605, 1718, 95, 5, 1...\n",
       "1397  [789, 1, 1, 1895, 488, 1318, 1495, 140, 1776, ...\n",
       "1398  [1996, 35, 12, 1995, 1999, 1, 1998, 31, 1917, ...\n",
       "1399  [966, 697, 842, 1113, 1770, 24, 1998, 8, 7, 62...\n",
       "\n",
       "[1400 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1999, 52, 1995, 1996, 2, 80, 1724, 1957, 1524...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1999, 1181, 50, 73, 1998, 1290, 1996, 9, 1412...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[1994, 1999, 181, 187, 1783, 1, 915, 1524, 292...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[827, 246, 1010, 1781, 11, 1999, 3, 1998, 823,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1063, 335, 78, 639, 1524, 25, 1957, 47, 17, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>[28, 1346, 1996, 1524, 1290, 397, 1205, 1770, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>[110, 11, 1205, 1770, 1996, 30, 397, 1899, 613...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>[1, 86, 22, 15, 41, 1998, 32, 1, 1999, 305, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>[97, 20, 302, 69, 1724, 1858, 569, 172, 90, 19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>[30, 1, 9, 1995, 1999, 250, 315, 1922, 116, 16...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               reviews\n",
       "0    [1999, 52, 1995, 1996, 2, 80, 1724, 1957, 1524...\n",
       "1    [1999, 1181, 50, 73, 1998, 1290, 1996, 9, 1412...\n",
       "2    [1994, 1999, 181, 187, 1783, 1, 915, 1524, 292...\n",
       "3    [827, 246, 1010, 1781, 11, 1999, 3, 1998, 823,...\n",
       "4    [1063, 335, 78, 639, 1524, 25, 1957, 47, 17, 1...\n",
       "..                                                 ...\n",
       "595  [28, 1346, 1996, 1524, 1290, 397, 1205, 1770, ...\n",
       "596  [110, 11, 1205, 1770, 1996, 30, 397, 1899, 613...\n",
       "597  [1, 86, 22, 15, 41, 1998, 32, 1, 1999, 305, 10...\n",
       "598  [97, 20, 302, 69, 1724, 1858, 569, 172, 90, 19...\n",
       "599  [30, 1, 9, 1995, 1999, 250, 315, 1922, 116, 16...\n",
       "\n",
       "[600 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "df_padded_train = pd.DataFrame(columns=[\"reviews\"])\n",
    "df_padded_train[\"reviews\"] = pad_sequences(df_encoded_train['reviews'], maxlen=L, padding='post', truncating='post').tolist()\n",
    "display(df_padded_train)\n",
    "df_padded_test = pd.DataFrame(columns=[\"reviews\"])\n",
    "df_padded_test[\"reviews\"] = pad_sequences(df_encoded_test['reviews'], maxlen=L, padding='post', truncating='post').tolist()\n",
    "display(df_padded_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f05172",
   "metadata": {},
   "source": [
    "<h2><center>Part c) Word Embeddings</center></h2><hr>\n",
    "<b> \n",
    "(i) One can use tokenized text as inputs to a deep neural network. However, a recent breakthrough in NLP suggests that more sophisticated representations of text yield better results. These sophisticated representations are called word\n",
    "embeddings. “Word embedding is a term used for representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning.”. Most deep learning modules (including Keras) provide a convenient way to convert positive integer representations of words into a word embedding by an “Embedding layer.” The layer accepts arguments that define the mapping of words into embeddings including the maximum number of expected words also called the vocabulary size (e.g. the largest integer value). The layer also allows you to specify the dimension for each word vector, called the “output dimension.” We would like\n",
    "to use a word embedding layer for this project. Assume that we are interested in the top 5,000 words. This means that in each integer sequence that represents each document, we set to zero those integers that represent words that are not among the top 5,000 words in the document.If you feel more adventurous, use all the words that appear in this corpus. Choose the length of the embedding vector for each word to be 32. Hence, each document is represented as a 32 × L matrix.\n",
    " \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609e7e1",
   "metadata": {},
   "source": [
    "<b><br>(ii)Flatten the matrix of each document to a vector</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4074aadb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The selected L value is :  383\n",
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_15 (Embedding)    (None, 383, 32)           160000    \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 12256)             0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 12257     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 172,257\n",
      "Trainable params: 172,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.preprocessing import text\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "\n",
    "vocab_size = 5000\n",
    "print(\"The selected L value is : \",L)\n",
    "# define class labels\n",
    "labels_train = list(df_tokenized_train['encoding'].values)\n",
    "padded_list_train = list(df_padded_train['reviews'].values)\n",
    "labels_test = list(df_tokenized_test['encoding'].values)\n",
    "padded_list_test = list(df_padded_test['reviews'].values)\n",
    "\n",
    "# define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 32, input_length=L))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# summarize the model\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a4e9f",
   "metadata": {},
   "source": [
    "<h2><center>Part d) Multi-Layer Perceptron</center></h2><hr>\n",
    "<b> \n",
    "(i) Train a MLP with three (dense) hidden layers each of which has 50 ReLUs and one output layer with a single sigmoid neuron. Use a dropout rate of 20% for the first layer and 50% for the other layers. Use ADAM optimizer and binary cross entropy loss (which is equivalent to having a softmax in the output). To avoid overfitting, just set the number of epochs as 2. Use a batch size of 10\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b74bc914",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143104b2eb0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the keras model\n",
    "# The model expects rows of data with 8 variables (the input_dim=8 argument)\n",
    "# The first hidden layer has 12 nodes and uses the relu activation function.\n",
    "# The second hidden layer has 8 nodes and uses the relu activation function.\n",
    "# The output layer has one node and uses the sigmoid activation function.\n",
    "modelMLP = Sequential()\n",
    "modelMLP.add(Embedding(vocab_size, 32, input_length=L))\n",
    "modelMLP.add(Flatten())\n",
    "modelMLP.add(Dense(50, input_dim=8, activation='relu',name = \"layer1\"))\n",
    "modelMLP.add(Dropout(0.2))\n",
    "modelMLP.add(Dense(50, activation='relu', name = \"layer2\"))\n",
    "modelMLP.add(Dropout(0.5))\n",
    "modelMLP.add(Dense(50, activation='relu', name = \"layer3\"))\n",
    "modelMLP.add(Dense(1, activation='sigmoid'))\n",
    "modelMLP.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "modelMLP.fit(padded_list_train, labels_train, epochs=2,verbose=0, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1748768",
   "metadata": {},
   "source": [
    "<b><br>(ii)Report the train and test accuracies of this model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8409a207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 95.642859\n",
      "Test Accuracy: 50.333333\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = modelMLP.evaluate(np.array(padded_list_train), np.array(labels_train), verbose=0)\n",
    "print('Train Accuracy: %f' % (accuracy*100))\n",
    "loss, accuracy = modelMLP.evaluate(np.array(padded_list_test), np.array(labels_test), verbose=0)\n",
    "print('Test Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505355b2",
   "metadata": {},
   "source": [
    "<h2><center>Part e) One-Dimensional Convolutional Neural Network</center></h2><hr>\n",
    "<b>Although CNNs are mainly used for image data, they can also be applied to text data, as text also has adjacency information. Keras supports one-dimensional convolutions and pooling by the Conv1D and MaxPooling1D classes respectively.\n",
    "<br><br>(i) After the embedding layer, insert a Conv1D layer. This convolutional layer has 32 feature maps , and each of the 32 kernels has size 3, i.e. reads embedded word representations 3 vector elements of the word embedding at a time. The convolutional layer is followed by a 1D max pooling layer with a length and stride of 2 that halves the size of the feature maps from the convolutional layer. The rest of the network is the same as the neural network above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d465526a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x143074b4fd0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelCNN = Sequential()\n",
    "modelCNN.add(Embedding(vocab_size, 32, input_length=L))\n",
    "modelCNN.add(layers.Conv1D(32, 3))\n",
    "modelCNN.add(layers.MaxPooling1D(2,2))\n",
    "modelCNN.add(Flatten())\n",
    "\n",
    "modelCNN.add(Dense(50, activation='relu',name = \"layer1\"))\n",
    "modelCNN.add(Dropout(0.2))\n",
    "modelCNN.add(Dense(50, activation='relu', name = \"layer2\"))\n",
    "modelCNN.add(Dropout(0.5))\n",
    "modelCNN.add(Dense(50, activation='relu', name = \"layer3\"))\n",
    "modelCNN.add(Dense(1, activation='sigmoid'))\n",
    "modelCNN.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "modelCNN.fit(padded_list_train, labels_train, epochs=2,verbose=0, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5311ebd7",
   "metadata": {},
   "source": [
    "<b><br>(ii)Report the train and test accuracies of this model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1c233fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 82.428569\n",
      "Test Accuracy: 57.166666\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = modelCNN.evaluate(np.array(padded_list_train), np.array(labels_train), verbose=0)\n",
    "print('Train Accuracy: %f' % (accuracy*100))\n",
    "loss, accuracy = modelCNN.evaluate(np.array(padded_list_test), np.array(labels_test), verbose=0)\n",
    "print('Test Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3906506",
   "metadata": {},
   "source": [
    "<h2><center>Part f) Long Short-Term Memory Recurrent Neural Network</center></h2><hr>\n",
    "<b>The structure of the LSTM we are going to use is shown in the following figure.\n",
    "(i)Each word is represented to LSTM as a vector of 32 elements and the LSTM\n",
    "is followed by a dense layer of 256 ReLUs. Use a dropout rate of 0.2 for both\n",
    "LSTM and the dense layer. Train the model using 10-50 epochs and batch\n",
    "size of 10\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2c0a2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 383, 32)           160000    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 12256)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 12257     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 172,257\n",
      "Trainable params: 172,257\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "140/140 [==============================] - 16s 102ms/step - loss: 0.6925 - accuracy: 0.5214 - val_loss: 0.6917 - val_accuracy: 0.5250\n",
      "Epoch 2/10\n",
      "140/140 [==============================] - 14s 103ms/step - loss: 0.6787 - accuracy: 0.5664 - val_loss: 0.6947 - val_accuracy: 0.5333\n",
      "Epoch 3/10\n",
      "140/140 [==============================] - 14s 103ms/step - loss: 0.6354 - accuracy: 0.6107 - val_loss: 0.7751 - val_accuracy: 0.5300\n",
      "Epoch 4/10\n",
      "140/140 [==============================] - 13s 95ms/step - loss: 0.6019 - accuracy: 0.6379 - val_loss: 0.8201 - val_accuracy: 0.5233\n",
      "Epoch 5/10\n",
      "140/140 [==============================] - 14s 101ms/step - loss: 0.5453 - accuracy: 0.6436 - val_loss: 0.9527 - val_accuracy: 0.5283\n",
      "Epoch 6/10\n",
      "140/140 [==============================] - 13s 90ms/step - loss: 0.5084 - accuracy: 0.6636 - val_loss: 1.0625 - val_accuracy: 0.5267\n",
      "Epoch 7/10\n",
      "140/140 [==============================] - 14s 101ms/step - loss: 0.4857 - accuracy: 0.6764 - val_loss: 1.2622 - val_accuracy: 0.5333\n",
      "Epoch 8/10\n",
      "140/140 [==============================] - 14s 97ms/step - loss: 0.4659 - accuracy: 0.6857 - val_loss: 1.4801 - val_accuracy: 0.5200\n",
      "Epoch 9/10\n",
      "140/140 [==============================] - 14s 99ms/step - loss: 0.4607 - accuracy: 0.6886 - val_loss: 1.5029 - val_accuracy: 0.5283\n",
      "Epoch 10/10\n",
      "140/140 [==============================] - 13s 96ms/step - loss: 0.4803 - accuracy: 0.6786 - val_loss: 1.4552 - val_accuracy: 0.5317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14306fd9dc0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelLSTM = Sequential()\n",
    "modelLSTM.add(Embedding(vocab_size, 32, input_length=L))\n",
    "modelLSTM.add(LSTM(32))\n",
    "modelLSTM.add(Dropout(0.2))\n",
    "modelLSTM.add(Dense(256, activation='relu'))\n",
    "modelLSTM.add(Dropout(0.2))\n",
    "modelLSTM.add(Dense(1, activation='sigmoid'))\n",
    "modelLSTM.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "modelLSTM.fit(padded_list_train, labels_train, validation_data=(padded_list_test, labels_test), epochs=10, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f1b6ab",
   "metadata": {},
   "source": [
    "<b><br>(ii)Report the train and test accuracies of this model.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6022e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 69.000000\n",
      "Test Accuracy: 53.166670\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = modelLSTM.evaluate(np.array(padded_list_train), np.array(labels_train), verbose=0)\n",
    "print('Train Accuracy: %f' % (accuracy*100))\n",
    "loss, accuracy = modelLSTM.evaluate(np.array(padded_list_test), np.array(labels_test), verbose=0)\n",
    "print('Test Accuracy: %f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f84d8c7",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
